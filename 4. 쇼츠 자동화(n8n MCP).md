# 쇼츠 자동화 시스템 개요

## 1. 시스템 목표 및 특징
   *   귀엽고 재밌는 유머러스한 동물 쇼츠 영상 제작
   *   자동화 범위: 캐릭터 디자인, 스토리 기획, 이미지 생성, 영상 제작, 나레이션, 자막, 배경 음악, 편집 효과, 피드백 반영 등 100% 자동 완성
   *   기존 방식과의 차이점:
        *   영상 편집 툴 불필요: 프리미어, 캡컷 등 수작업 편집 없이 자동화
        *   계획 자동화: 캐릭터부터 스토리까지 GPT(4o-mini)가 알아서 다함
        *   대화형 피드백 반영: 캐릭터 표정, 의상 변경 등 부분 편집 및 효과 삽입, 피드백 반영을 대화로 해결
        *   일관성/품질 관리: 캐릭터 일관성, 스토리 퀄리티 자동 관리

## 2. 핵심 구성 요소

### 2.1. MCP (Model Context Protocol)
   *   역할: GPT가 디렉터이자 편집자 역할 동시 수행
   *   N8N 제어: N8N의 모든 제작 파이프라인 동시 제어
   *   서버 구축: MCP 서버 트리거 노드 추가, URL 자동 생성 및 GPT에 연결
   *   보안: Bearer Authentication 설정, 토큰 생성으로 원격 접속 차단
   *   도구 연결:
        *   N8N 워크플로 툴: N8N 워크플로를 도구화하여 MCP에 연결
            *   이름: 영문명 권장
            *   설명: 에이전트 이해를 돕기 위해 상세 설명 추가 (영문/한글 무관)
            *   인자값(파라미터): 추가 디스크립션으로 에이전트 혼동 방지

### 2.2. N8N (Workflow Automation Tool)
   *   워크플로우 타입:
        *   순차적인 워크플로: 유연성 없고 수정 불가
        *   에이전틱 타입: GPT가 디렉터/편집자 역할을 하며 유연성 높음
   *   주요 노드:
        *   Trigger (When executed by another workflow): 다른 워크플로우에서 호출할 수 있는 트리거 노드
            *   입력 방식: 유필드 벨로우(여러 파라미터 수신)
            *   데이터 타입: 문자열(String), 숫자, 참/거짓(Boolean), 배열, 객체 지원
        *   AI Agent 노드:
            *   프롬프트: 일반 지침, 세부 지침으로 나눠 전달하여 에이전트 이해도 향상
            *   LLM 모델: OpenRouter (다수 모델 통합 API), OpenAI, 4o-mini, Gemini 등 교체 가능
            *   파서 구조: 원하는 JSON 응답 구조 부여
            *   Auto-fix Format: LLM의 JSON 형식 오류 발생 시 자동 교정 (구조 복잡할 경우 유용)
        *   HTTP Request 노드: Replicate, File AI 등 전용 노드 없을 때 API 요청에 사용
            *   메서드: GET (일반 정보 요청), POST (특정 쿼리문 전송)
            *   헤더: `Prefer: wait` (응답 대기) 등 설정
            *   인증: Bearer Token 등
        *   S3 Upload 노드 (AWS S3): 이미지, 오디오, 영상 등 파일 저장 및 주소 반환
            *   URL 필요성: 구글 드라이브와 달리 퍼블릭 URI 지속 제공
            *   설정: 버킷명, 파일 경로명 지정 (아이디 값 활용하여 중복 방지)
            *   퍼블릭 URI: CloudFront CDN 서비스를 통해 가져옴
        *   If 노드: 조건에 따라 참/거짓 경로로 분기
        *   Wait 노드: 일정 시간 대기 (예: 동영상 생성 완료 대기 시 GPT 세션 끊김 방지)
        *   Aggregate 노드: 여러 주소(예: 6개 장면 URL)를 배열 형태로 집계하여 처리 용이하게 함
        *   Field Set 노드: 상수값 정의 및 반환
    *   커스텀 노드:
        *   ElevenLabs N8N 노드: 자연스러운 나레이션(성우 목소리) 생성
            *   보이스 설정: 다양한 보이스 선택, 사용자 목소리 복제 기능
            *   상세 세팅: 안정성, 일관성, 톤, 속도 조절 가능
            *   다국어 지원: 한국어 지원 모델 활용
        *   Media FX N8N 노드: 영상 렌더링 전용 커스텀 노드 (개발자 자체 개발)
            *   비용 절감: Creatomate, Zayson Video 등 유료 API 대체
            *   기능: 영상 병합, 자르기, 전환 효과(페이드인/아웃, 와이프, 슬라이드 등), 오디오 추출/믹스, 자막 삽입, 이미지-비디오 변환, 스탬프 이미지, 폰트 지원 등
            *   자막 삽입: 특정 구간 지정, 폰트(한글 지원 폰트 포함), 사이즈, 색상, 위치 등 설정
            *   나레이션/배경 음악 믹스: 볼륨 조절, 특정 구간 삽입(Partial Mix), 반복 재생, 페이드인/아웃 효과

## 3. 콘텐츠 제작 파이프라인 (단계별)
   *   전체 오케스트레이션: GPT(4o-mini)가 각 N8N 워크플로 도구를 호출하며 전체 흐름 제어
   *   1단계: 스토리 기획
       *   도구: "제넬레 숏 비디오 스토리 (Generate Short Video Story)"
       *   LLM: Gemini 2.5 Pro (기획 품질 중시)
       *   결과: 6개 장면 플롯 기획, AI 이미지 생성용 영어 프롬프트, 자막(12자 이내), 나레이션 지침 생성
   *   2단계: 캐릭터/이미지 생성
       *   도구: "AI Image"
       *   이미지 모델: 플럭스(Playback)의 데브 모델 (이미지 퀄리티 중시)
       *   일관성 유지: 3D 애니메이션/디즈니/픽사 스타일의 서픽스(Suffix) 프롬프트 사용
       *   API: Replicate API 활용 (HTTP Request 노드)
       *   이미지 편집 (선택 사항): "AI Image Editor" - Gemini API 활용, 특정 부분 수정하여 이미지 일관성 유지
   *   3단계: 비디오 생성
       *   도구: "제넬의 이미지 비디오 (Generate AI Video)"
       *   서비스: File AI (Click 2.1 모델) - 이미지/동영상 AI 모델 API 서비스
       *   입력: 이미지 URL만 전달 (프롬프트 제공 시 부자연스러운 경험 방지)
       *   GPT 세션 제한(32초) 고려: 생성 요청과 상태 확인/다운로드 분리
   *   4단계: 비디오 다운로드
       *   도구: "다운로드 제레이트 AI 비디오 (Download Generated AI Video)"
       *   역할: 생성 상태 조회(2회 진행), 미생성 시 GPT에게 다시 요청하도록 알림
   *   5단계: 나레이션 생성
       *   도구: "제넬의 이미지 나레이션 (Generate Narration)"
       *   서비스: ElevenLabs
       *   N8N 노드: ElevenLabs 커스텀 노드 사용
   *   6단계: 최종 렌더링
       *   도구: "렌더링 파이널 쇼츠 비디오 (Render Final Shorts Video)"
       *   N8N 노드: Media FX 커스텀 노드 활용
       *   과정:
           *   장면별 데이터셋 수신
           *   배경 음악 고정값으로 삽입 (AI 생성 가능)
           *   루프 노드를 통해 장면별 동영상 생성 (자막, 나레이션 삽입)
           *   Aggreagate 노드로 영상 주소 취합
           *   영상 병합 및 전환 효과(페이드인/아웃 등) 삽입
           *   배경 음악 믹스 (볼륨 조절, 길이 조절, 페이드아웃)
           *   S3에 최종 영상 저장 후 URL 리턴

## 4. GPT(4o-mini) 연동 및 활용
   *   연동 방법:
       *   GPT '검색 및 도구'에서 '통합 추가하기'
       *   연동 이름, MCP 서버 트리거의 프로덕션 URL 입력
       *   N8N MCP 서버 워크플로우 활성화 확인
   *   프롬프트 지침:
       *   목표: 명확한 전체 목표 제시 (예: 6개 장면 동물 쇼츠 영상 제작)
       *   도구 사용 지시: "무조건 MCP를 사용해라"
       *   컨셉: 캐릭터, 스토리 컨셉 제공 (예: 판교 햄스터 직장인 이야기)
       *   중간 결과물 출력 유도: 피드백/수정 요청을 위해 중간 과정 출력 요구
       *   단계별 지침: 기획, 이미지 생성, 동영상 생성, 렌더링 등 순차적 지시
       *   세부 지시: 배경 음악 URL 등 구체적 정보 제공
   *   GPT의 역할:
       *   오케스트레이션: 각 단계별 워크플로 도구들을 활용하여 전체 흐름을 컨트롤
       *   실패 제어: 워크플로 실패 시 GPT가 시나리오들을 컨트롤하여 강건하게 처리
   *   피드백 반영: 특정 장면 수정 요청 시, GPT가 해당 부분만 수정하여 동영상 다시 렌더링 가능

## 5. 주요 장점
   *   완전 자동화: 기획부터 제작, 편집까지 모든 과정 자동화
   *   높은 유연성: 짜여진 시나리오가 아닌 실제 업무처럼 에이전트와 대화하며 피드백 및 제작
   *   강력한 도구 조합: MCP와 N8N의 조합으로 다양한 목표 달성 가능
   *   안정성: MCP 도구 사용 시 거의 실수 없이 안정적으로 진행
   *   비용 절감: Media FX 커스텀 노드를 통해 유료 렌더링 API 서비스 불필요

## 6. 추가 정보
   *   가이드 및 강의: MCP 서버 구축, Replicate API 사용, S3 설정, CloudFront 설정 등 상세 가이드 제공


## 초롱이 영상 모음
[![초롱이 쇼츠 #1](https://img.youtube.com/vi/MytKkev4qaw/0.jpg)](https://youtube.com/shorts/MytKkev4qaw?feature=share)  
[![초롱이 쇼츠 #2](https://img.youtube.com/vi/JeNg1QdQW4I/0.jpg)](https://youtube.com/shorts/JeNg1QdQW4I?feature=share)  
[![초롱이 쇼츠 #3](https://img.youtube.com/vi/S_WVLGNs_FE/0.jpg)](https://youtube.com/shorts/S_WVLGNs_FE?feature=share)  
